{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Loading the necessary libraries\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "\n",
    "\n",
    "cust = pd.read_csv('custody_ML.csv')\n",
    "shoot = pd.read_csv('shootings_ML.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>dept</th>\n",
       "      <th>custody_type</th>\n",
       "      <th>facility</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>death_type</th>\n",
       "      <th>charge_status</th>\n",
       "      <th>age</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>389</td>\n",
       "      <td>2</td>\n",
       "      <td>134</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>389</td>\n",
       "      <td>2</td>\n",
       "      <td>115</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>175</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>389</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>2011</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>389</td>\n",
       "      <td>2</td>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  dept  custody_type  facility  race  sex  death_type  \\\n",
       "0           0   389             2       134     4    1           5   \n",
       "1           1   389             2       115     3    1           5   \n",
       "2           2   175             1         0     4    1           6   \n",
       "3           3   389             2        60     1    1           1   \n",
       "4           4   389             2        77     1    1           5   \n",
       "\n",
       "   charge_status   age  year  month  \n",
       "0              0  58.0  2012      9  \n",
       "1              0  76.0  2016      9  \n",
       "2              2  30.0  2016     12  \n",
       "3              0  39.0  2011     11  \n",
       "4              0  31.0  2014     12  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cust.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>age</th>\n",
       "      <th>number_officers</th>\n",
       "      <th>fatality</th>\n",
       "      <th>armed</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>stop_reason</th>\n",
       "      <th>officer_race</th>\n",
       "      <th>dept</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>103</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>104</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>105</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>86</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>107</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>2011</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   age  number_officers  fatality  armed  race  sex  stop_reason  \\\n",
       "0         103  26.0              1.0         0      2     4    1           23   \n",
       "1         104  16.0              1.0         0      2     2    1           13   \n",
       "2         105  26.0              2.0         0      2     0    1           66   \n",
       "3         106  35.0              1.0         0      0     4    1           86   \n",
       "4         107  30.0              1.0         0      2     2    1           66   \n",
       "\n",
       "   officer_race  dept  year  month  \n",
       "0            13     0  2010      9  \n",
       "1            40     0  2010     10  \n",
       "2            48     0  2010     11  \n",
       "3             5     0  2010     12  \n",
       "4            13     0  2011      5  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shoot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "shoot.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dept</th>\n",
       "      <th>custody_type</th>\n",
       "      <th>facility</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>death_type</th>\n",
       "      <th>charge_status</th>\n",
       "      <th>age</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.555878</td>\n",
       "      <td>0.123491</td>\n",
       "      <td>0.230097</td>\n",
       "      <td>1.156565</td>\n",
       "      <td>0.238506</td>\n",
       "      <td>0.155584</td>\n",
       "      <td>-0.605742</td>\n",
       "      <td>0.590814</td>\n",
       "      <td>0.412088</td>\n",
       "      <td>0.723706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.555878</td>\n",
       "      <td>0.123491</td>\n",
       "      <td>-0.095784</td>\n",
       "      <td>0.406515</td>\n",
       "      <td>0.238506</td>\n",
       "      <td>0.155584</td>\n",
       "      <td>-0.605742</td>\n",
       "      <td>1.798521</td>\n",
       "      <td>1.579194</td>\n",
       "      <td>0.723706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.378794</td>\n",
       "      <td>-1.037655</td>\n",
       "      <td>-2.068228</td>\n",
       "      <td>1.156565</td>\n",
       "      <td>0.238506</td>\n",
       "      <td>0.943599</td>\n",
       "      <td>1.487142</td>\n",
       "      <td>-1.287842</td>\n",
       "      <td>1.579194</td>\n",
       "      <td>1.595334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.555878</td>\n",
       "      <td>0.123491</td>\n",
       "      <td>-1.039127</td>\n",
       "      <td>-1.093584</td>\n",
       "      <td>0.238506</td>\n",
       "      <td>-2.996475</td>\n",
       "      <td>-0.605742</td>\n",
       "      <td>-0.683988</td>\n",
       "      <td>0.120312</td>\n",
       "      <td>1.304791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.555878</td>\n",
       "      <td>0.123491</td>\n",
       "      <td>-0.747548</td>\n",
       "      <td>-1.093584</td>\n",
       "      <td>0.238506</td>\n",
       "      <td>0.155584</td>\n",
       "      <td>-0.605742</td>\n",
       "      <td>-1.220747</td>\n",
       "      <td>0.995641</td>\n",
       "      <td>1.595334</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       dept  custody_type  facility      race       sex  death_type  \\\n",
       "0  0.555878      0.123491  0.230097  1.156565  0.238506    0.155584   \n",
       "1  0.555878      0.123491 -0.095784  0.406515  0.238506    0.155584   \n",
       "2 -1.378794     -1.037655 -2.068228  1.156565  0.238506    0.943599   \n",
       "3  0.555878      0.123491 -1.039127 -1.093584  0.238506   -2.996475   \n",
       "4  0.555878      0.123491 -0.747548 -1.093584  0.238506    0.155584   \n",
       "\n",
       "   charge_status       age      year     month  \n",
       "0      -0.605742  0.590814  0.412088  0.723706  \n",
       "1      -0.605742  1.798521  1.579194  0.723706  \n",
       "2       1.487142 -1.287842  1.579194  1.595334  \n",
       "3      -0.605742 -0.683988  0.120312  1.304791  \n",
       "4      -0.605742 -1.220747  0.995641  1.595334  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scale cust df\n",
    "X_col = cust.columns\n",
    "\n",
    "cust_scaled = pd.DataFrame(StandardScaler().fit_transform(cust), columns= X_col)\n",
    "cust_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>number_officers</th>\n",
       "      <th>fatality</th>\n",
       "      <th>armed</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>stop_reason</th>\n",
       "      <th>officer_race</th>\n",
       "      <th>dept</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.670348</td>\n",
       "      <td>-0.394330</td>\n",
       "      <td>-1.387608</td>\n",
       "      <td>0.980761</td>\n",
       "      <td>1.548471</td>\n",
       "      <td>-0.543893</td>\n",
       "      <td>-1.792733</td>\n",
       "      <td>-1.051157</td>\n",
       "      <td>-1.900016</td>\n",
       "      <td>-1.560899</td>\n",
       "      <td>0.761520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.716530</td>\n",
       "      <td>-0.394330</td>\n",
       "      <td>-1.387608</td>\n",
       "      <td>0.980761</td>\n",
       "      <td>-0.096378</td>\n",
       "      <td>-0.543893</td>\n",
       "      <td>-2.118722</td>\n",
       "      <td>0.439038</td>\n",
       "      <td>-1.900016</td>\n",
       "      <td>-1.560899</td>\n",
       "      <td>1.051969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.670348</td>\n",
       "      <td>0.469955</td>\n",
       "      <td>-1.387608</td>\n",
       "      <td>0.980761</td>\n",
       "      <td>-1.741227</td>\n",
       "      <td>-0.543893</td>\n",
       "      <td>-0.390982</td>\n",
       "      <td>0.880578</td>\n",
       "      <td>-1.900016</td>\n",
       "      <td>-1.560899</td>\n",
       "      <td>1.342418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.271215</td>\n",
       "      <td>-0.394330</td>\n",
       "      <td>-1.387608</td>\n",
       "      <td>-1.040776</td>\n",
       "      <td>1.548471</td>\n",
       "      <td>-0.543893</td>\n",
       "      <td>0.260995</td>\n",
       "      <td>-1.492696</td>\n",
       "      <td>-1.900016</td>\n",
       "      <td>-1.560899</td>\n",
       "      <td>1.632866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.251876</td>\n",
       "      <td>-0.394330</td>\n",
       "      <td>-1.387608</td>\n",
       "      <td>0.980761</td>\n",
       "      <td>-0.096378</td>\n",
       "      <td>-0.543893</td>\n",
       "      <td>-0.390982</td>\n",
       "      <td>-1.051157</td>\n",
       "      <td>-1.900016</td>\n",
       "      <td>-1.048604</td>\n",
       "      <td>-0.400275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  number_officers  fatality     armed      race       sex  \\\n",
       "0 -0.670348        -0.394330 -1.387608  0.980761  1.548471 -0.543893   \n",
       "1 -1.716530        -0.394330 -1.387608  0.980761 -0.096378 -0.543893   \n",
       "2 -0.670348         0.469955 -1.387608  0.980761 -1.741227 -0.543893   \n",
       "3  0.271215        -0.394330 -1.387608 -1.040776  1.548471 -0.543893   \n",
       "4 -0.251876        -0.394330 -1.387608  0.980761 -0.096378 -0.543893   \n",
       "\n",
       "   stop_reason  officer_race      dept      year     month  \n",
       "0    -1.792733     -1.051157 -1.900016 -1.560899  0.761520  \n",
       "1    -2.118722      0.439038 -1.900016 -1.560899  1.051969  \n",
       "2    -0.390982      0.880578 -1.900016 -1.560899  1.342418  \n",
       "3     0.260995     -1.492696 -1.900016 -1.560899  1.632866  \n",
       "4    -0.390982     -1.051157 -1.900016 -1.048604 -0.400275  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scale shoot df\n",
    "X_cols = shoot.columns\n",
    "\n",
    "shoot_scaled = pd.DataFrame(StandardScaler().fit_transform(shoot), columns = X_cols)\n",
    "shoot_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create training and testing groups of data\n",
    "train_cust, test_cust= train_test_split(cust_scaled, test_size = 0.2, random_state = 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of clusters, 2, and silhouette coefficient is 0.28\n",
      "The number of clusters, 3, and silhouette coefficient is 0.31\n",
      "The number of clusters, 4, and silhouette coefficient is 0.32\n",
      "The number of clusters, 5, and silhouette coefficient is 0.18\n",
      "The number of clusters, 6, and silhouette coefficient is 0.17\n",
      "The number of clusters, 7, and silhouette coefficient is 0.18\n",
      "The number of clusters, 8, and silhouette coefficient is 0.18\n",
      "The number of clusters, 9, and silhouette coefficient is 0.18\n",
      "The number of clusters, 10, and silhouette coefficient is 0.17\n"
     ]
    }
   ],
   "source": [
    "#KMeans Clustering\n",
    "k_range = range(2,11)\n",
    "\n",
    "for i in k_range:\n",
    "    model = KMeans(n_clusters=i,random_state=11)\n",
    "    pred =model.fit_predict(train_cust)\n",
    "    silhouette_avg = silhouette_score(train_cust,pred)\n",
    "    print('The number of clusters, %d, and silhouette coefficient is %0.2f'% (i,silhouette_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Coefficient: 0.162\n"
     ]
    }
   ],
   "source": [
    "# Affinity propagation\n",
    "affPro = AffinityPropagation()\n",
    "affPro.fit_predict(train_cust)\n",
    "centers = affPro.cluster_centers_indices_\n",
    "labels = affPro.labels_\n",
    "print(\"Silhouette Coefficient: %0.3f\"% silhouette_score(train_cust, labels, metric='euclidean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tuning Affinity Propogation\n",
    "def grid_aff(parameters, x):\n",
    "    kfold = model_selection.KFold(n_splits=10, shuffle = True, random_state=11)\n",
    "    aff = AffinityPropagation()\n",
    "    clf = GridSearchCV(aff, parameters, n_jobs =-1, cv = kfold, scoring='adjusted_mutual_info_score')\n",
    "    clf.fit(x)\n",
    "    \n",
    "    print(clf.best_estimator_)\n",
    "    print(clf.best_score_)\n",
    "    print(clf.cluster_centers_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "JoblibTypeError",
     "evalue": "JoblibTypeError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\nC:\\Users\\Lara\\Miniconda3\\lib\\runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\nC:\\Users\\Lara\\Miniconda3\\lib\\runpy.py in _run_code(code=<code object <module> at 0x000001E6DBF37B70, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\Lara\\Miniconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\Users\\Lara\\Miniconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\L...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x000001E6DBF37B70, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\Lara\\Miniconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\Users\\Lara\\Miniconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\L...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\nC:\\Users\\Lara\\Miniconda3\\lib\\site-packages\\ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\nC:\\Users\\Lara\\Miniconda3\\lib\\site-packages\\traitlets\\config\\application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\nC:\\Users\\Lara\\Miniconda3\\lib\\site-packages\\ipykernel\\kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         self.io_loop = ioloop.IOLoop.current()\n    477         try:\n--> 478             self.io_loop.start()\n        self.io_loop.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    479         except KeyboardInterrupt:\n    480             pass\n    481 \n    482 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\nC:\\Users\\Lara\\Miniconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\nC:\\Users\\Lara\\Miniconda3\\lib\\site-packages\\tornado\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\nC:\\Users\\Lara\\Miniconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\nC:\\Users\\Lara\\Miniconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\nC:\\Users\\Lara\\Miniconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\nC:\\Users\\Lara\\Miniconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\nC:\\Users\\Lara\\Miniconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\nC:\\Users\\Lara\\Miniconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    276         if self.control_stream:\n    277             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    278 \n    279         def make_dispatcher(stream):\n    280             def dispatcher(msg):\n--> 281                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    282             return dispatcher\n    283 \n    284         for s in self.shell_streams:\n    285             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\nC:\\Users\\Lara\\Miniconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': \"param_grid = {'damping': [0.5,0.75, 1], 'max_ite...'True','False']}\\ngrid_aff(param_grid, train_cust)\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 1, 29, 22, 43, 2, 387131, tzinfo=tzutc()), 'msg_id': 'E3D7BF9AD35C48469FE1A959F2F59FE9', 'msg_type': 'execute_request', 'session': '1F5C1AC651564E9E8E3A00FE0AE30290', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'E3D7BF9AD35C48469FE1A959F2F59FE9', 'msg_type': 'execute_request', 'parent_header': {}})\n    227             self.log.warn(\"Unknown message type: %r\", msg_type)\n    228         else:\n    229             self.log.debug(\"%s: %s\", msg_type, msg)\n    230             self.pre_handler_hook()\n    231             try:\n--> 232                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'1F5C1AC651564E9E8E3A00FE0AE30290']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': \"param_grid = {'damping': [0.5,0.75, 1], 'max_ite...'True','False']}\\ngrid_aff(param_grid, train_cust)\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 1, 29, 22, 43, 2, 387131, tzinfo=tzutc()), 'msg_id': 'E3D7BF9AD35C48469FE1A959F2F59FE9', 'msg_type': 'execute_request', 'session': '1F5C1AC651564E9E8E3A00FE0AE30290', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'E3D7BF9AD35C48469FE1A959F2F59FE9', 'msg_type': 'execute_request', 'parent_header': {}}\n    233             except Exception:\n    234                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    235             finally:\n    236                 self.post_handler_hook()\n\n...........................................................................\nC:\\Users\\Lara\\Miniconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'1F5C1AC651564E9E8E3A00FE0AE30290'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': \"param_grid = {'damping': [0.5,0.75, 1], 'max_ite...'True','False']}\\ngrid_aff(param_grid, train_cust)\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 1, 29, 22, 43, 2, 387131, tzinfo=tzutc()), 'msg_id': 'E3D7BF9AD35C48469FE1A959F2F59FE9', 'msg_type': 'execute_request', 'session': '1F5C1AC651564E9E8E3A00FE0AE30290', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'E3D7BF9AD35C48469FE1A959F2F59FE9', 'msg_type': 'execute_request', 'parent_header': {}})\n    392         if not silent:\n    393             self.execution_count += 1\n    394             self._publish_execute_input(code, parent, self.execution_count)\n    395 \n    396         reply_content = self.do_execute(code, silent, store_history,\n--> 397                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    398 \n    399         # Flush output before sending the reply.\n    400         sys.stdout.flush()\n    401         sys.stderr.flush()\n\n...........................................................................\nC:\\Users\\Lara\\Miniconda3\\lib\\site-packages\\ipykernel\\ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=\"param_grid = {'damping': [0.5,0.75, 1], 'max_ite...'True','False']}\\ngrid_aff(param_grid, train_cust)\", silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    203 \n    204         self._forward_input(allow_stdin)\n    205 \n    206         reply_content = {}\n    207         try:\n--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = \"param_grid = {'damping': [0.5,0.75, 1], 'max_ite...'True','False']}\\ngrid_aff(param_grid, train_cust)\"\n        store_history = True\n        silent = False\n    209         finally:\n    210             self._restore_input()\n    211 \n    212         if res.error_before_exec is not None:\n\n...........................................................................\nC:\\Users\\Lara\\Miniconda3\\lib\\site-packages\\ipykernel\\zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(\"param_grid = {'damping': [0.5,0.75, 1], 'max_ite...'True','False']}\\ngrid_aff(param_grid, train_cust)\",), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (\"param_grid = {'damping': [0.5,0.75, 1], 'max_ite...'True','False']}\\ngrid_aff(param_grid, train_cust)\",)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\nC:\\Users\\Lara\\Miniconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=\"param_grid = {'damping': [0.5,0.75, 1], 'max_ite...'True','False']}\\ngrid_aff(param_grid, train_cust)\", store_history=True, silent=False, shell_futures=True)\n   2723                 self.displayhook.exec_result = result\n   2724 \n   2725                 # Execute the user code\n   2726                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2727                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2728                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2729                 \n   2730                 self.last_execution_succeeded = not has_raised\n   2731                 self.last_execution_result = result\n   2732 \n\n...........................................................................\nC:\\Users\\Lara\\Miniconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Expr object>], cell_name='<ipython-input-42-6d5282d5cdf9>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 1e692470550, executio..._before_exec=None error_in_exec=None result=None>)\n   2851                     return True\n   2852 \n   2853             for i, node in enumerate(to_run_interactive):\n   2854                 mod = ast.Interactive([node])\n   2855                 code = compiler(mod, cell_name, \"single\")\n-> 2856                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x000001E692428E40, file \"<ipython-input-42-6d5282d5cdf9>\", line 2>\n        result = <ExecutionResult object at 1e692470550, executio..._before_exec=None error_in_exec=None result=None>\n   2857                     return True\n   2858 \n   2859             # Flush softspace\n   2860             if softspace(sys.stdout, 0):\n\n...........................................................................\nC:\\Users\\Lara\\Miniconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x000001E692428E40, file \"<ipython-input-42-6d5282d5cdf9>\", line 2>, result=<ExecutionResult object at 1e692470550, executio..._before_exec=None error_in_exec=None result=None>)\n   2905         outflag = True  # happens in more places, so it's easier as default\n   2906         try:\n   2907             try:\n   2908                 self.hooks.pre_run_code_hook()\n   2909                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2910                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x000001E692428E40, file \"<ipython-input-42-6d5282d5cdf9>\", line 2>\n        self.user_global_ns = {'AffinityPropagation': <class 'sklearn.cluster.affinity_propagation_.AffinityPropagation'>, 'AgglomerativeClustering': <class 'sklearn.cluster.hierarchical.AgglomerativeClustering'>, 'DBSCAN': <class 'sklearn.cluster.dbscan_.DBSCAN'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', \"import pandas as pd\\nimport numpy as np\\n\\n# Loadin..._ML.csv')\\nshoot = pd.read_csv('shootings_ML.csv')\", 'cust.head()', 'shoot.head()', \"cust.drop('Unnamed: 0', axis=1, inplace=True)\", \"shoot.drop('Unnamed: 0', axis=1, inplace=True)\", '#Scale cust df\\nX_col = cust.columns\\n\\ncust_scaled...ansform(cust), columns= X_col)\\ncust_scaled.head()', '#Scale shoot df\\nX_cols = shoot.columns\\n\\nshoot_sc...orm(shoot), columns = X_cols)\\nshoot_scaled.head()', '#create training and testing groups of data\\ntrai...(cust_scaled, test_size = 0.2, random_state = 11)', \"#KMeans Clustering\\nk_range = range(2,11)\\n\\nfor i ...ouette coefficient is %0.2f'% (i,silhouette_avg))\", \"# Affinity propagation\\naffPro = AffinityPropagat...te_score(train_cust, labels, metric='euclidean'))\", '# Spectral clustering\\n\\nfor k in range(2,11):\\n   ...and silhouette coefficient is %0.2f\" % (k,score))', \"# Using PCA for dimensionality reduction\\nP= PCA(...'str')\\n\\nprint(data_1.pred_cluster.value_counts())\", '#Tuning Affinity Propogation\\ndef grid_aff(parame...t clf.best_score_\\n    print clf.cluster_centers_ ', '#Tuning Affinity Propogation\\ndef grid_aff(parame...t clf.best_score_\\n    print clf.cluster_centers_ ', '#Tuning Affinity Propogation\\ndef grid_aff(parame...t clf.best_score_\\n    print(clf.cluster_centers_)', '#Tuning Affinity Propogation\\ndef grid_aff(parame...(clf.best_score_)\\n    print(clf.cluster_centers_)', \"param_grid = {'damping': [0.5,0.75, 1], 'max_ite...'True','False']}\\ngrid_aff(param_grid, train_cust)\", \"import pandas as pd\\nimport numpy as np\\n\\n# Loadin..._ML.csv')\\nshoot = pd.read_csv('shootings_ML.csv')\", \"import pandas as pd\\nimport numpy as np\\n\\n# Loadin..._ML.csv')\\nshoot = pd.read_csv('shootings_ML.csv')\", ...], 'KFold': <class 'sklearn.model_selection._split.KFold'>, 'KMeans': <class 'sklearn.cluster.k_means_.KMeans'>, 'Out': {2:    Unnamed: 0  dept  custody_type  facility  rac...11     11  \n4              0  31.0  2014     12  , 3:    Unnamed: 0   age  number_officers  fatality  ...010     12  \n4            13     0  2011      5  , 6:        dept  custody_type  facility      race   ...\n4      -0.605742 -1.220747  0.995641  1.595334  , 7:         age  number_officers  fatality     armed...982     -1.051157 -1.900016 -1.048604 -0.400275  , 20:    Unnamed: 0  dept  custody_type  facility  rac...11     11  \n4              0  31.0  2014     12  , 21:    Unnamed: 0   age  number_officers  fatality  ...010     12  \n4            13     0  2011      5  , 24:        dept  custody_type  facility      race   ...\n4      -0.605742 -1.220747  0.995641  1.595334  , 25:         age  number_officers  fatality     armed...982     -1.051157 -1.900016 -1.048604 -0.400275  , 34:        dept  custody_type  facility      race   ...\n4      -0.605742 -1.220747  0.995641  1.595334  , 35:         age  number_officers  fatality     armed...982     -1.051157 -1.900016 -1.048604 -0.400275  , ...}, 'P': PCA(copy=True, iterated_power='auto', n_componen...None,\n  svd_solver='auto', tol=0.0, whiten=False), 'PCA': <class 'sklearn.decomposition.pca.PCA'>, ...}\n        self.user_ns = {'AffinityPropagation': <class 'sklearn.cluster.affinity_propagation_.AffinityPropagation'>, 'AgglomerativeClustering': <class 'sklearn.cluster.hierarchical.AgglomerativeClustering'>, 'DBSCAN': <class 'sklearn.cluster.dbscan_.DBSCAN'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', \"import pandas as pd\\nimport numpy as np\\n\\n# Loadin..._ML.csv')\\nshoot = pd.read_csv('shootings_ML.csv')\", 'cust.head()', 'shoot.head()', \"cust.drop('Unnamed: 0', axis=1, inplace=True)\", \"shoot.drop('Unnamed: 0', axis=1, inplace=True)\", '#Scale cust df\\nX_col = cust.columns\\n\\ncust_scaled...ansform(cust), columns= X_col)\\ncust_scaled.head()', '#Scale shoot df\\nX_cols = shoot.columns\\n\\nshoot_sc...orm(shoot), columns = X_cols)\\nshoot_scaled.head()', '#create training and testing groups of data\\ntrai...(cust_scaled, test_size = 0.2, random_state = 11)', \"#KMeans Clustering\\nk_range = range(2,11)\\n\\nfor i ...ouette coefficient is %0.2f'% (i,silhouette_avg))\", \"# Affinity propagation\\naffPro = AffinityPropagat...te_score(train_cust, labels, metric='euclidean'))\", '# Spectral clustering\\n\\nfor k in range(2,11):\\n   ...and silhouette coefficient is %0.2f\" % (k,score))', \"# Using PCA for dimensionality reduction\\nP= PCA(...'str')\\n\\nprint(data_1.pred_cluster.value_counts())\", '#Tuning Affinity Propogation\\ndef grid_aff(parame...t clf.best_score_\\n    print clf.cluster_centers_ ', '#Tuning Affinity Propogation\\ndef grid_aff(parame...t clf.best_score_\\n    print clf.cluster_centers_ ', '#Tuning Affinity Propogation\\ndef grid_aff(parame...t clf.best_score_\\n    print(clf.cluster_centers_)', '#Tuning Affinity Propogation\\ndef grid_aff(parame...(clf.best_score_)\\n    print(clf.cluster_centers_)', \"param_grid = {'damping': [0.5,0.75, 1], 'max_ite...'True','False']}\\ngrid_aff(param_grid, train_cust)\", \"import pandas as pd\\nimport numpy as np\\n\\n# Loadin..._ML.csv')\\nshoot = pd.read_csv('shootings_ML.csv')\", \"import pandas as pd\\nimport numpy as np\\n\\n# Loadin..._ML.csv')\\nshoot = pd.read_csv('shootings_ML.csv')\", ...], 'KFold': <class 'sklearn.model_selection._split.KFold'>, 'KMeans': <class 'sklearn.cluster.k_means_.KMeans'>, 'Out': {2:    Unnamed: 0  dept  custody_type  facility  rac...11     11  \n4              0  31.0  2014     12  , 3:    Unnamed: 0   age  number_officers  fatality  ...010     12  \n4            13     0  2011      5  , 6:        dept  custody_type  facility      race   ...\n4      -0.605742 -1.220747  0.995641  1.595334  , 7:         age  number_officers  fatality     armed...982     -1.051157 -1.900016 -1.048604 -0.400275  , 20:    Unnamed: 0  dept  custody_type  facility  rac...11     11  \n4              0  31.0  2014     12  , 21:    Unnamed: 0   age  number_officers  fatality  ...010     12  \n4            13     0  2011      5  , 24:        dept  custody_type  facility      race   ...\n4      -0.605742 -1.220747  0.995641  1.595334  , 25:         age  number_officers  fatality     armed...982     -1.051157 -1.900016 -1.048604 -0.400275  , 34:        dept  custody_type  facility      race   ...\n4      -0.605742 -1.220747  0.995641  1.595334  , 35:         age  number_officers  fatality     armed...982     -1.051157 -1.900016 -1.048604 -0.400275  , ...}, 'P': PCA(copy=True, iterated_power='auto', n_componen...None,\n  svd_solver='auto', tol=0.0, whiten=False), 'PCA': <class 'sklearn.decomposition.pca.PCA'>, ...}\n   2911             finally:\n   2912                 # Reset our crash handler in place\n   2913                 sys.excepthook = old_excepthook\n   2914         except SystemExit as e:\n\n...........................................................................\nC:\\Users\\Lara\\Documents\\Repository\\Capstone2\\<ipython-input-42-6d5282d5cdf9> in <module>()\n      1 param_grid = {'damping': [0.5,0.75, 1], 'max_iter': [50, 100, 200, 300, 350], 'convergence_iter': [7, 15, 23], 'verbose':['True','False']}\n----> 2 grid_aff(param_grid, train_cust)\n\n...........................................................................\nC:\\Users\\Lara\\Documents\\Repository\\Capstone2\\<ipython-input-38-66de2106d230> in grid_aff(parameters={'convergence_iter': [7, 15, 23], 'damping': [0.5, 0.75, 1], 'max_iter': [50, 100, 200, 300, 350], 'verbose': ['True', 'False']}, x=          dept  custody_type  facility      race...9  1.287418  1.595334  \n\n[6183 rows x 10 columns])\n      1 #Tuning Affinity Propogation\n      2 def grid_aff(parameters, x):\n      3     kfold = model_selection.KFold(n_splits=10, shuffle = True, random_state=11)\n      4     aff = AffinityPropagation()\n      5     clf = GridSearchCV(aff, parameters, n_jobs =-1, cv = kfold, scoring='adjusted_mutual_info_score')\n----> 6     clf.fit(x)\n      7     \n      8     print(clf.best_estimator_)\n      9     print(clf.best_score_)\n     10     print(clf.cluster_centers_)\n\n...........................................................................\nC:\\Users\\Lara\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py in fit(self=GridSearchCV(cv=KFold(n_splits=10, random_state=... scoring='adjusted_mutual_info_score', verbose=0), X=          dept  custody_type  facility      race...9  1.287418  1.595334  \n\n[6183 rows x 10 columns], y=None, groups=None, **fit_params={})\n    634                                   return_train_score=self.return_train_score,\n    635                                   return_n_test_samples=True,\n    636                                   return_times=True, return_parameters=False,\n    637                                   error_score=self.error_score)\n    638           for parameters, (train, test) in product(candidate_params,\n--> 639                                                    cv.split(X, y, groups)))\n        cv.split = <bound method _BaseKFold.split of KFold(n_splits=10, random_state=11, shuffle=True)>\n        X =           dept  custody_type  facility      race...9  1.287418  1.595334  \n\n[6183 rows x 10 columns]\n        y = None\n        groups = None\n    640 \n    641         # if one choose to see train score, \"out\" will contain train score info\n    642         if self.return_train_score:\n    643             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\nC:\\Users\\Lara\\Miniconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV.fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nTypeError                                          Mon Jan 29 16:45:44 2018\nPID: 7568                 Python 3.6.3: C:\\Users\\Lara\\Miniconda3\\python.exe\n...........................................................................\nC:\\Users\\Lara\\Miniconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (AffinityPropagation(affinity='euclidean', conver....5, max_iter=50, preference=None, verbose='True'),           dept  custody_type  facility      race...9  1.287418  1.595334  \n\n[6183 rows x 10 columns], None, {'score': make_scorer(adjusted_mutual_info_score)}, array([   0,    2,    3, ..., 6180, 6181, 6182]), array([   1,    5,   15,   32,   36,   42,   47,...6135, 6139, 6149, 6152,\n       6158, 6161, 6162]), 0, {'convergence_iter': 7, 'damping': 0.5, 'max_iter': 50, 'verbose': 'True'}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Lara\\Miniconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (AffinityPropagation(affinity='euclidean', conver....5, max_iter=50, preference=None, verbose='True'),           dept  custody_type  facility      race...9  1.287418  1.595334  \n\n[6183 rows x 10 columns], None, {'score': make_scorer(adjusted_mutual_info_score)}, array([   0,    2,    3, ..., 6180, 6181, 6182]), array([   1,    5,   15,   32,   36,   42,   47,...6135, 6139, 6149, 6152,\n       6158, 6161, 6162]), 0, {'convergence_iter': 7, 'damping': 0.5, 'max_iter': 50, 'verbose': 'True'})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Lara\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=AffinityPropagation(affinity='euclidean', conver....5, max_iter=50, preference=None, verbose='True'), X=          dept  custody_type  facility      race...9  1.287418  1.595334  \n\n[6183 rows x 10 columns], y=None, scorer={'score': make_scorer(adjusted_mutual_info_score)}, train=array([   0,    2,    3, ..., 6180, 6181, 6182]), test=array([   1,    5,   15,   32,   36,   42,   47,...6135, 6139, 6149, 6152,\n       6158, 6161, 6162]), verbose=0, parameters={'convergence_iter': 7, 'damping': 0.5, 'max_iter': 50, 'verbose': 'True'}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    483                              \" make sure that it has been spelled correctly.)\")\n    484 \n    485     else:\n    486         fit_time = time.time() - start_time\n    487         # _score will return dict if is_multimetric is True\n--> 488         test_scores = _score(estimator, X_test, y_test, scorer, is_multimetric)\n        test_scores = {}\n        estimator = AffinityPropagation(affinity='euclidean', conver....5, max_iter=50, preference=None, verbose='True')\n        X_test =           dept  custody_type  facility      race...14  0.995641  0.142621  \n\n[619 rows x 10 columns]\n        y_test = None\n        scorer = {'score': make_scorer(adjusted_mutual_info_score)}\n        is_multimetric = True\n    489         score_time = time.time() - start_time - fit_time\n    490         if return_train_score:\n    491             train_scores = _score(estimator, X_train, y_train, scorer,\n    492                                   is_multimetric)\n\n...........................................................................\nC:\\Users\\Lara\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _score(estimator=AffinityPropagation(affinity='euclidean', conver....5, max_iter=50, preference=None, verbose='True'), X_test=          dept  custody_type  facility      race...14  0.995641  0.142621  \n\n[619 rows x 10 columns], y_test=None, scorer={'score': make_scorer(adjusted_mutual_info_score)}, is_multimetric=True)\n    518 \n    519     Will return a single float if is_multimetric is False and a dict of floats,\n    520     if is_multimetric is True\n    521     \"\"\"\n    522     if is_multimetric:\n--> 523         return _multimetric_score(estimator, X_test, y_test, scorer)\n        estimator = AffinityPropagation(affinity='euclidean', conver....5, max_iter=50, preference=None, verbose='True')\n        X_test =           dept  custody_type  facility      race...14  0.995641  0.142621  \n\n[619 rows x 10 columns]\n        y_test = None\n        scorer = {'score': make_scorer(adjusted_mutual_info_score)}\n    524     else:\n    525         if y_test is None:\n    526             score = scorer(estimator, X_test)\n    527         else:\n\n...........................................................................\nC:\\Users\\Lara\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _multimetric_score(estimator=AffinityPropagation(affinity='euclidean', conver....5, max_iter=50, preference=None, verbose='True'), X_test=          dept  custody_type  facility      race...14  0.995641  0.142621  \n\n[619 rows x 10 columns], y_test=None, scorers={'score': make_scorer(adjusted_mutual_info_score)})\n    546     \"\"\"Return a dict of score for multimetric scoring\"\"\"\n    547     scores = {}\n    548 \n    549     for name, scorer in scorers.items():\n    550         if y_test is None:\n--> 551             score = scorer(estimator, X_test)\n        score = undefined\n        scorer = make_scorer(adjusted_mutual_info_score)\n        estimator = AffinityPropagation(affinity='euclidean', conver....5, max_iter=50, preference=None, verbose='True')\n        X_test =           dept  custody_type  facility      race...14  0.995641  0.142621  \n\n[619 rows x 10 columns]\n    552         else:\n    553             score = scorer(estimator, X_test, y_test)\n    554 \n    555         if hasattr(score, 'item'):\n\nTypeError: __call__() missing 1 required positional argument: 'y_true'\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\Lara\\Miniconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 350, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\Lara\\Miniconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"C:\\Users\\Lara\\Miniconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"C:\\Users\\Lara\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 488, in _fit_and_score\n    test_scores = _score(estimator, X_test, y_test, scorer, is_multimetric)\n  File \"C:\\Users\\Lara\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 523, in _score\n    return _multimetric_score(estimator, X_test, y_test, scorer)\n  File \"C:\\Users\\Lara\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 551, in _multimetric_score\n    score = scorer(estimator, X_test)\nTypeError: __call__() missing 1 required positional argument: 'y_true'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\Lara\\Miniconda3\\lib\\multiprocessing\\pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"C:\\Users\\Lara\\Miniconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 359, in __call__\n    raise TransportableException(text, e_type)\nsklearn.externals.joblib.my_exceptions.TransportableException: TransportableException\n___________________________________________________________________________\nTypeError                                          Mon Jan 29 16:45:44 2018\nPID: 7568                 Python 3.6.3: C:\\Users\\Lara\\Miniconda3\\python.exe\n...........................................................................\nC:\\Users\\Lara\\Miniconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (AffinityPropagation(affinity='euclidean', conver....5, max_iter=50, preference=None, verbose='True'),           dept  custody_type  facility      race...9  1.287418  1.595334  \n\n[6183 rows x 10 columns], None, {'score': make_scorer(adjusted_mutual_info_score)}, array([   0,    2,    3, ..., 6180, 6181, 6182]), array([   1,    5,   15,   32,   36,   42,   47,...6135, 6139, 6149, 6152,\n       6158, 6161, 6162]), 0, {'convergence_iter': 7, 'damping': 0.5, 'max_iter': 50, 'verbose': 'True'}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Lara\\Miniconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (AffinityPropagation(affinity='euclidean', conver....5, max_iter=50, preference=None, verbose='True'),           dept  custody_type  facility      race...9  1.287418  1.595334  \n\n[6183 rows x 10 columns], None, {'score': make_scorer(adjusted_mutual_info_score)}, array([   0,    2,    3, ..., 6180, 6181, 6182]), array([   1,    5,   15,   32,   36,   42,   47,...6135, 6139, 6149, 6152,\n       6158, 6161, 6162]), 0, {'convergence_iter': 7, 'damping': 0.5, 'max_iter': 50, 'verbose': 'True'})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Lara\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=AffinityPropagation(affinity='euclidean', conver....5, max_iter=50, preference=None, verbose='True'), X=          dept  custody_type  facility      race...9  1.287418  1.595334  \n\n[6183 rows x 10 columns], y=None, scorer={'score': make_scorer(adjusted_mutual_info_score)}, train=array([   0,    2,    3, ..., 6180, 6181, 6182]), test=array([   1,    5,   15,   32,   36,   42,   47,...6135, 6139, 6149, 6152,\n       6158, 6161, 6162]), verbose=0, parameters={'convergence_iter': 7, 'damping': 0.5, 'max_iter': 50, 'verbose': 'True'}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    483                              \" make sure that it has been spelled correctly.)\")\n    484 \n    485     else:\n    486         fit_time = time.time() - start_time\n    487         # _score will return dict if is_multimetric is True\n--> 488         test_scores = _score(estimator, X_test, y_test, scorer, is_multimetric)\n        test_scores = {}\n        estimator = AffinityPropagation(affinity='euclidean', conver....5, max_iter=50, preference=None, verbose='True')\n        X_test =           dept  custody_type  facility      race...14  0.995641  0.142621  \n\n[619 rows x 10 columns]\n        y_test = None\n        scorer = {'score': make_scorer(adjusted_mutual_info_score)}\n        is_multimetric = True\n    489         score_time = time.time() - start_time - fit_time\n    490         if return_train_score:\n    491             train_scores = _score(estimator, X_train, y_train, scorer,\n    492                                   is_multimetric)\n\n...........................................................................\nC:\\Users\\Lara\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _score(estimator=AffinityPropagation(affinity='euclidean', conver....5, max_iter=50, preference=None, verbose='True'), X_test=          dept  custody_type  facility      race...14  0.995641  0.142621  \n\n[619 rows x 10 columns], y_test=None, scorer={'score': make_scorer(adjusted_mutual_info_score)}, is_multimetric=True)\n    518 \n    519     Will return a single float if is_multimetric is False and a dict of floats,\n    520     if is_multimetric is True\n    521     \"\"\"\n    522     if is_multimetric:\n--> 523         return _multimetric_score(estimator, X_test, y_test, scorer)\n        estimator = AffinityPropagation(affinity='euclidean', conver....5, max_iter=50, preference=None, verbose='True')\n        X_test =           dept  custody_type  facility      race...14  0.995641  0.142621  \n\n[619 rows x 10 columns]\n        y_test = None\n        scorer = {'score': make_scorer(adjusted_mutual_info_score)}\n    524     else:\n    525         if y_test is None:\n    526             score = scorer(estimator, X_test)\n    527         else:\n\n...........................................................................\nC:\\Users\\Lara\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _multimetric_score(estimator=AffinityPropagation(affinity='euclidean', conver....5, max_iter=50, preference=None, verbose='True'), X_test=          dept  custody_type  facility      race...14  0.995641  0.142621  \n\n[619 rows x 10 columns], y_test=None, scorers={'score': make_scorer(adjusted_mutual_info_score)})\n    546     \"\"\"Return a dict of score for multimetric scoring\"\"\"\n    547     scores = {}\n    548 \n    549     for name, scorer in scorers.items():\n    550         if y_test is None:\n--> 551             score = scorer(estimator, X_test)\n        score = undefined\n        scorer = make_scorer(adjusted_mutual_info_score)\n        estimator = AffinityPropagation(affinity='euclidean', conver....5, max_iter=50, preference=None, verbose='True')\n        X_test =           dept  custody_type  facility      race...14  0.995641  0.142621  \n\n[619 rows x 10 columns]\n    552         else:\n    553             score = scorer(estimator, X_test, y_test)\n    554 \n    555         if hasattr(score, 'item'):\n\nTypeError: __call__() missing 1 required positional argument: 'y_true'\n___________________________________________________________________________\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    700\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    643\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 644\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    645\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nTypeError                                          Mon Jan 29 16:45:44 2018\nPID: 7568                 Python 3.6.3: C:\\Users\\Lara\\Miniconda3\\python.exe\n...........................................................................\nC:\\Users\\Lara\\Miniconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (AffinityPropagation(affinity='euclidean', conver....5, max_iter=50, preference=None, verbose='True'),           dept  custody_type  facility      race...9  1.287418  1.595334  \n\n[6183 rows x 10 columns], None, {'score': make_scorer(adjusted_mutual_info_score)}, array([   0,    2,    3, ..., 6180, 6181, 6182]), array([   1,    5,   15,   32,   36,   42,   47,...6135, 6139, 6149, 6152,\n       6158, 6161, 6162]), 0, {'convergence_iter': 7, 'damping': 0.5, 'max_iter': 50, 'verbose': 'True'}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Lara\\Miniconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (AffinityPropagation(affinity='euclidean', conver....5, max_iter=50, preference=None, verbose='True'),           dept  custody_type  facility      race...9  1.287418  1.595334  \n\n[6183 rows x 10 columns], None, {'score': make_scorer(adjusted_mutual_info_score)}, array([   0,    2,    3, ..., 6180, 6181, 6182]), array([   1,    5,   15,   32,   36,   42,   47,...6135, 6139, 6149, 6152,\n       6158, 6161, 6162]), 0, {'convergence_iter': 7, 'damping': 0.5, 'max_iter': 50, 'verbose': 'True'})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Lara\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=AffinityPropagation(affinity='euclidean', conver....5, max_iter=50, preference=None, verbose='True'), X=          dept  custody_type  facility      race...9  1.287418  1.595334  \n\n[6183 rows x 10 columns], y=None, scorer={'score': make_scorer(adjusted_mutual_info_score)}, train=array([   0,    2,    3, ..., 6180, 6181, 6182]), test=array([   1,    5,   15,   32,   36,   42,   47,...6135, 6139, 6149, 6152,\n       6158, 6161, 6162]), verbose=0, parameters={'convergence_iter': 7, 'damping': 0.5, 'max_iter': 50, 'verbose': 'True'}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    483                              \" make sure that it has been spelled correctly.)\")\n    484 \n    485     else:\n    486         fit_time = time.time() - start_time\n    487         # _score will return dict if is_multimetric is True\n--> 488         test_scores = _score(estimator, X_test, y_test, scorer, is_multimetric)\n        test_scores = {}\n        estimator = AffinityPropagation(affinity='euclidean', conver....5, max_iter=50, preference=None, verbose='True')\n        X_test =           dept  custody_type  facility      race...14  0.995641  0.142621  \n\n[619 rows x 10 columns]\n        y_test = None\n        scorer = {'score': make_scorer(adjusted_mutual_info_score)}\n        is_multimetric = True\n    489         score_time = time.time() - start_time - fit_time\n    490         if return_train_score:\n    491             train_scores = _score(estimator, X_train, y_train, scorer,\n    492                                   is_multimetric)\n\n...........................................................................\nC:\\Users\\Lara\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _score(estimator=AffinityPropagation(affinity='euclidean', conver....5, max_iter=50, preference=None, verbose='True'), X_test=          dept  custody_type  facility      race...14  0.995641  0.142621  \n\n[619 rows x 10 columns], y_test=None, scorer={'score': make_scorer(adjusted_mutual_info_score)}, is_multimetric=True)\n    518 \n    519     Will return a single float if is_multimetric is False and a dict of floats,\n    520     if is_multimetric is True\n    521     \"\"\"\n    522     if is_multimetric:\n--> 523         return _multimetric_score(estimator, X_test, y_test, scorer)\n        estimator = AffinityPropagation(affinity='euclidean', conver....5, max_iter=50, preference=None, verbose='True')\n        X_test =           dept  custody_type  facility      race...14  0.995641  0.142621  \n\n[619 rows x 10 columns]\n        y_test = None\n        scorer = {'score': make_scorer(adjusted_mutual_info_score)}\n    524     else:\n    525         if y_test is None:\n    526             score = scorer(estimator, X_test)\n    527         else:\n\n...........................................................................\nC:\\Users\\Lara\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _multimetric_score(estimator=AffinityPropagation(affinity='euclidean', conver....5, max_iter=50, preference=None, verbose='True'), X_test=          dept  custody_type  facility      race...14  0.995641  0.142621  \n\n[619 rows x 10 columns], y_test=None, scorers={'score': make_scorer(adjusted_mutual_info_score)})\n    546     \"\"\"Return a dict of score for multimetric scoring\"\"\"\n    547     scores = {}\n    548 \n    549     for name, scorer in scorers.items():\n    550         if y_test is None:\n--> 551             score = scorer(estimator, X_test)\n        score = undefined\n        scorer = make_scorer(adjusted_mutual_info_score)\n        estimator = AffinityPropagation(affinity='euclidean', conver....5, max_iter=50, preference=None, verbose='True')\n        X_test =           dept  custody_type  facility      race...14  0.995641  0.142621  \n\n[619 rows x 10 columns]\n    552         else:\n    553             score = scorer(estimator, X_test, y_test)\n    554 \n    555         if hasattr(score, 'item'):\n\nTypeError: __call__() missing 1 required positional argument: 'y_true'\n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mJoblibTypeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-6d5282d5cdf9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mparam_grid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'damping'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.75\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'max_iter'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m350\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'convergence_iter'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m23\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'verbose'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'True'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'False'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mgrid_aff\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_cust\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-38-66de2106d230>\u001b[0m in \u001b[0;36mgrid_aff\u001b[1;34m(parameters, x)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0maff\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAffinityPropagation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maff\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkfold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adjusted_mutual_info_score'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[1;32m--> 639\u001b[1;33m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m         \u001b[1;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    787\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 789\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    790\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    738\u001b[0m                     \u001b[0mexception\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexception_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    739\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 740\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    742\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mJoblibTypeError\u001b[0m: JoblibTypeError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\nC:\\Users\\Lara\\Miniconda3\\lib\\runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\nC:\\Users\\Lara\\Miniconda3\\lib\\runpy.py in _run_code(code=<code object <module> at 0x000001E6DBF37B70, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\Lara\\Miniconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\Users\\Lara\\Miniconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\L...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x000001E6DBF37B70, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\Lara\\Miniconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\Users\\Lara\\Miniconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\L...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\nC:\\Users\\Lara\\Miniconda3\\lib\\site-packages\\ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\nC:\\Users\\Lara\\Miniconda3\\lib\\site-packages\\traitlets\\config\\application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\nC:\\Users\\Lara\\Miniconda3\\lib\\site-packages\\ipykernel\\kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         self.io_loop = ioloop.IOLoop.current()\n    477         try:\n--> 478             self.io_loop.start()\n        self.io_loop.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    479         except KeyboardInterrupt:\n    480             pass\n    481 \n    482 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\nC:\\Users\\Lara\\Miniconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\nC:\\Users\\Lara\\Miniconda3\\lib\\site-packages\\tornado\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\nC:\\Users\\Lara\\Miniconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\nC:\\Users\\Lara\\Miniconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\nC:\\Users\\Lara\\Miniconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\nC:\\Users\\Lara\\Miniconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\nC:\\Users\\Lara\\Miniconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\nC:\\Users\\Lara\\Miniconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    276         if self.control_stream:\n    277             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    278 \n    279         def make_dispatcher(stream):\n    280             def dispatcher(msg):\n--> 281                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    282             return dispatcher\n    283 \n    284         for s in self.shell_streams:\n    285             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\nC:\\Users\\Lara\\Miniconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': \"param_grid = {'damping': [0.5,0.75, 1], 'max_ite...'True','False']}\\ngrid_aff(param_grid, train_cust)\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 1, 29, 22, 43, 2, 387131, tzinfo=tzutc()), 'msg_id': 'E3D7BF9AD35C48469FE1A959F2F59FE9', 'msg_type': 'execute_request', 'session': '1F5C1AC651564E9E8E3A00FE0AE30290', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'E3D7BF9AD35C48469FE1A959F2F59FE9', 'msg_type': 'execute_request', 'parent_header': {}})\n    227             self.log.warn(\"Unknown message type: %r\", msg_type)\n    228         else:\n    229             self.log.debug(\"%s: %s\", msg_type, msg)\n    230             self.pre_handler_hook()\n    231             try:\n--> 232                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'1F5C1AC651564E9E8E3A00FE0AE30290']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': \"param_grid = {'damping': [0.5,0.75, 1], 'max_ite...'True','False']}\\ngrid_aff(param_grid, train_cust)\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 1, 29, 22, 43, 2, 387131, tzinfo=tzutc()), 'msg_id': 'E3D7BF9AD35C48469FE1A959F2F59FE9', 'msg_type': 'execute_request', 'session': '1F5C1AC651564E9E8E3A00FE0AE30290', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'E3D7BF9AD35C48469FE1A959F2F59FE9', 'msg_type': 'execute_request', 'parent_header': {}}\n    233             except Exception:\n    234                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    235             finally:\n    236                 self.post_handler_hook()\n\n...........................................................................\nC:\\Users\\Lara\\Miniconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'1F5C1AC651564E9E8E3A00FE0AE30290'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': \"param_grid = {'damping': [0.5,0.75, 1], 'max_ite...'True','False']}\\ngrid_aff(param_grid, train_cust)\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 1, 29, 22, 43, 2, 387131, tzinfo=tzutc()), 'msg_id': 'E3D7BF9AD35C48469FE1A959F2F59FE9', 'msg_type': 'execute_request', 'session': '1F5C1AC651564E9E8E3A00FE0AE30290', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'E3D7BF9AD35C48469FE1A959F2F59FE9', 'msg_type': 'execute_request', 'parent_header': {}})\n    392         if not silent:\n    393             self.execution_count += 1\n    394             self._publish_execute_input(code, parent, self.execution_count)\n    395 \n    396         reply_content = self.do_execute(code, silent, store_history,\n--> 397                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    398 \n    399         # Flush output before sending the reply.\n    400         sys.stdout.flush()\n    401         sys.stderr.flush()\n\n...........................................................................\nC:\\Users\\Lara\\Miniconda3\\lib\\site-packages\\ipykernel\\ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=\"param_grid = {'damping': [0.5,0.75, 1], 'max_ite...'True','False']}\\ngrid_aff(param_grid, train_cust)\", silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    203 \n    204         self._forward_input(allow_stdin)\n    205 \n    206         reply_content = {}\n    207         try:\n--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = \"param_grid = {'damping': [0.5,0.75, 1], 'max_ite...'True','False']}\\ngrid_aff(param_grid, train_cust)\"\n        store_history = True\n        silent = False\n    209         finally:\n    210             self._restore_input()\n    211 \n    212         if res.error_before_exec is not None:\n\n...........................................................................\nC:\\Users\\Lara\\Miniconda3\\lib\\site-packages\\ipykernel\\zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(\"param_grid = {'damping': [0.5,0.75, 1], 'max_ite...'True','False']}\\ngrid_aff(param_grid, train_cust)\",), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (\"param_grid = {'damping': [0.5,0.75, 1], 'max_ite...'True','False']}\\ngrid_aff(param_grid, train_cust)\",)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\nC:\\Users\\Lara\\Miniconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=\"param_grid = {'damping': [0.5,0.75, 1], 'max_ite...'True','False']}\\ngrid_aff(param_grid, train_cust)\", store_history=True, silent=False, shell_futures=True)\n   2723                 self.displayhook.exec_result = result\n   2724 \n   2725                 # Execute the user code\n   2726                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2727                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2728                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2729                 \n   2730                 self.last_execution_succeeded = not has_raised\n   2731                 self.last_execution_result = result\n   2732 \n\n...........................................................................\nC:\\Users\\Lara\\Miniconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Expr object>], cell_name='<ipython-input-42-6d5282d5cdf9>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 1e692470550, executio..._before_exec=None error_in_exec=None result=None>)\n   2851                     return True\n   2852 \n   2853             for i, node in enumerate(to_run_interactive):\n   2854                 mod = ast.Interactive([node])\n   2855                 code = compiler(mod, cell_name, \"single\")\n-> 2856                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x000001E692428E40, file \"<ipython-input-42-6d5282d5cdf9>\", line 2>\n        result = <ExecutionResult object at 1e692470550, executio..._before_exec=None error_in_exec=None result=None>\n   2857                     return True\n   2858 \n   2859             # Flush softspace\n   2860             if softspace(sys.stdout, 0):\n\n...........................................................................\nC:\\Users\\Lara\\Miniconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x000001E692428E40, file \"<ipython-input-42-6d5282d5cdf9>\", line 2>, result=<ExecutionResult object at 1e692470550, executio..._before_exec=None error_in_exec=None result=None>)\n   2905         outflag = True  # happens in more places, so it's easier as default\n   2906         try:\n   2907             try:\n   2908                 self.hooks.pre_run_code_hook()\n   2909                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2910                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x000001E692428E40, file \"<ipython-input-42-6d5282d5cdf9>\", line 2>\n        self.user_global_ns = {'AffinityPropagation': <class 'sklearn.cluster.affinity_propagation_.AffinityPropagation'>, 'AgglomerativeClustering': <class 'sklearn.cluster.hierarchical.AgglomerativeClustering'>, 'DBSCAN': <class 'sklearn.cluster.dbscan_.DBSCAN'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', \"import pandas as pd\\nimport numpy as np\\n\\n# Loadin..._ML.csv')\\nshoot = pd.read_csv('shootings_ML.csv')\", 'cust.head()', 'shoot.head()', \"cust.drop('Unnamed: 0', axis=1, inplace=True)\", \"shoot.drop('Unnamed: 0', axis=1, inplace=True)\", '#Scale cust df\\nX_col = cust.columns\\n\\ncust_scaled...ansform(cust), columns= X_col)\\ncust_scaled.head()', '#Scale shoot df\\nX_cols = shoot.columns\\n\\nshoot_sc...orm(shoot), columns = X_cols)\\nshoot_scaled.head()', '#create training and testing groups of data\\ntrai...(cust_scaled, test_size = 0.2, random_state = 11)', \"#KMeans Clustering\\nk_range = range(2,11)\\n\\nfor i ...ouette coefficient is %0.2f'% (i,silhouette_avg))\", \"# Affinity propagation\\naffPro = AffinityPropagat...te_score(train_cust, labels, metric='euclidean'))\", '# Spectral clustering\\n\\nfor k in range(2,11):\\n   ...and silhouette coefficient is %0.2f\" % (k,score))', \"# Using PCA for dimensionality reduction\\nP= PCA(...'str')\\n\\nprint(data_1.pred_cluster.value_counts())\", '#Tuning Affinity Propogation\\ndef grid_aff(parame...t clf.best_score_\\n    print clf.cluster_centers_ ', '#Tuning Affinity Propogation\\ndef grid_aff(parame...t clf.best_score_\\n    print clf.cluster_centers_ ', '#Tuning Affinity Propogation\\ndef grid_aff(parame...t clf.best_score_\\n    print(clf.cluster_centers_)', '#Tuning Affinity Propogation\\ndef grid_aff(parame...(clf.best_score_)\\n    print(clf.cluster_centers_)', \"param_grid = {'damping': [0.5,0.75, 1], 'max_ite...'True','False']}\\ngrid_aff(param_grid, train_cust)\", \"import pandas as pd\\nimport numpy as np\\n\\n# Loadin..._ML.csv')\\nshoot = pd.read_csv('shootings_ML.csv')\", \"import pandas as pd\\nimport numpy as np\\n\\n# Loadin..._ML.csv')\\nshoot = pd.read_csv('shootings_ML.csv')\", ...], 'KFold': <class 'sklearn.model_selection._split.KFold'>, 'KMeans': <class 'sklearn.cluster.k_means_.KMeans'>, 'Out': {2:    Unnamed: 0  dept  custody_type  facility  rac...11     11  \n4              0  31.0  2014     12  , 3:    Unnamed: 0   age  number_officers  fatality  ...010     12  \n4            13     0  2011      5  , 6:        dept  custody_type  facility      race   ...\n4      -0.605742 -1.220747  0.995641  1.595334  , 7:         age  number_officers  fatality     armed...982     -1.051157 -1.900016 -1.048604 -0.400275  , 20:    Unnamed: 0  dept  custody_type  facility  rac...11     11  \n4              0  31.0  2014     12  , 21:    Unnamed: 0   age  number_officers  fatality  ...010     12  \n4            13     0  2011      5  , 24:        dept  custody_type  facility      race   ...\n4      -0.605742 -1.220747  0.995641  1.595334  , 25:         age  number_officers  fatality     armed...982     -1.051157 -1.900016 -1.048604 -0.400275  , 34:        dept  custody_type  facility      race   ...\n4      -0.605742 -1.220747  0.995641  1.595334  , 35:         age  number_officers  fatality     armed...982     -1.051157 -1.900016 -1.048604 -0.400275  , ...}, 'P': PCA(copy=True, iterated_power='auto', n_componen...None,\n  svd_solver='auto', tol=0.0, whiten=False), 'PCA': <class 'sklearn.decomposition.pca.PCA'>, ...}\n        self.user_ns = {'AffinityPropagation': <class 'sklearn.cluster.affinity_propagation_.AffinityPropagation'>, 'AgglomerativeClustering': <class 'sklearn.cluster.hierarchical.AgglomerativeClustering'>, 'DBSCAN': <class 'sklearn.cluster.dbscan_.DBSCAN'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', \"import pandas as pd\\nimport numpy as np\\n\\n# Loadin..._ML.csv')\\nshoot = pd.read_csv('shootings_ML.csv')\", 'cust.head()', 'shoot.head()', \"cust.drop('Unnamed: 0', axis=1, inplace=True)\", \"shoot.drop('Unnamed: 0', axis=1, inplace=True)\", '#Scale cust df\\nX_col = cust.columns\\n\\ncust_scaled...ansform(cust), columns= X_col)\\ncust_scaled.head()', '#Scale shoot df\\nX_cols = shoot.columns\\n\\nshoot_sc...orm(shoot), columns = X_cols)\\nshoot_scaled.head()', '#create training and testing groups of data\\ntrai...(cust_scaled, test_size = 0.2, random_state = 11)', \"#KMeans Clustering\\nk_range = range(2,11)\\n\\nfor i ...ouette coefficient is %0.2f'% (i,silhouette_avg))\", \"# Affinity propagation\\naffPro = AffinityPropagat...te_score(train_cust, labels, metric='euclidean'))\", '# Spectral clustering\\n\\nfor k in range(2,11):\\n   ...and silhouette coefficient is %0.2f\" % (k,score))', \"# Using PCA for dimensionality reduction\\nP= PCA(...'str')\\n\\nprint(data_1.pred_cluster.value_counts())\", '#Tuning Affinity Propogation\\ndef grid_aff(parame...t clf.best_score_\\n    print clf.cluster_centers_ ', '#Tuning Affinity Propogation\\ndef grid_aff(parame...t clf.best_score_\\n    print clf.cluster_centers_ ', '#Tuning Affinity Propogation\\ndef grid_aff(parame...t clf.best_score_\\n    print(clf.cluster_centers_)', '#Tuning Affinity Propogation\\ndef grid_aff(parame...(clf.best_score_)\\n    print(clf.cluster_centers_)', \"param_grid = {'damping': [0.5,0.75, 1], 'max_ite...'True','False']}\\ngrid_aff(param_grid, train_cust)\", \"import pandas as pd\\nimport numpy as np\\n\\n# Loadin..._ML.csv')\\nshoot = pd.read_csv('shootings_ML.csv')\", \"import pandas as pd\\nimport numpy as np\\n\\n# Loadin..._ML.csv')\\nshoot = pd.read_csv('shootings_ML.csv')\", ...], 'KFold': <class 'sklearn.model_selection._split.KFold'>, 'KMeans': <class 'sklearn.cluster.k_means_.KMeans'>, 'Out': {2:    Unnamed: 0  dept  custody_type  facility  rac...11     11  \n4              0  31.0  2014     12  , 3:    Unnamed: 0   age  number_officers  fatality  ...010     12  \n4            13     0  2011      5  , 6:        dept  custody_type  facility      race   ...\n4      -0.605742 -1.220747  0.995641  1.595334  , 7:         age  number_officers  fatality     armed...982     -1.051157 -1.900016 -1.048604 -0.400275  , 20:    Unnamed: 0  dept  custody_type  facility  rac...11     11  \n4              0  31.0  2014     12  , 21:    Unnamed: 0   age  number_officers  fatality  ...010     12  \n4            13     0  2011      5  , 24:        dept  custody_type  facility      race   ...\n4      -0.605742 -1.220747  0.995641  1.595334  , 25:         age  number_officers  fatality     armed...982     -1.051157 -1.900016 -1.048604 -0.400275  , 34:        dept  custody_type  facility      race   ...\n4      -0.605742 -1.220747  0.995641  1.595334  , 35:         age  number_officers  fatality     armed...982     -1.051157 -1.900016 -1.048604 -0.400275  , ...}, 'P': PCA(copy=True, iterated_power='auto', n_componen...None,\n  svd_solver='auto', tol=0.0, whiten=False), 'PCA': <class 'sklearn.decomposition.pca.PCA'>, ...}\n   2911             finally:\n   2912                 # Reset our crash handler in place\n   2913                 sys.excepthook = old_excepthook\n   2914         except SystemExit as e:\n\n...........................................................................\nC:\\Users\\Lara\\Documents\\Repository\\Capstone2\\<ipython-input-42-6d5282d5cdf9> in <module>()\n      1 param_grid = {'damping': [0.5,0.75, 1], 'max_iter': [50, 100, 200, 300, 350], 'convergence_iter': [7, 15, 23], 'verbose':['True','False']}\n----> 2 grid_aff(param_grid, train_cust)\n\n...........................................................................\nC:\\Users\\Lara\\Documents\\Repository\\Capstone2\\<ipython-input-38-66de2106d230> in grid_aff(parameters={'convergence_iter': [7, 15, 23], 'damping': [0.5, 0.75, 1], 'max_iter': [50, 100, 200, 300, 350], 'verbose': ['True', 'False']}, x=          dept  custody_type  facility      race...9  1.287418  1.595334  \n\n[6183 rows x 10 columns])\n      1 #Tuning Affinity Propogation\n      2 def grid_aff(parameters, x):\n      3     kfold = model_selection.KFold(n_splits=10, shuffle = True, random_state=11)\n      4     aff = AffinityPropagation()\n      5     clf = GridSearchCV(aff, parameters, n_jobs =-1, cv = kfold, scoring='adjusted_mutual_info_score')\n----> 6     clf.fit(x)\n      7     \n      8     print(clf.best_estimator_)\n      9     print(clf.best_score_)\n     10     print(clf.cluster_centers_)\n\n...........................................................................\nC:\\Users\\Lara\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py in fit(self=GridSearchCV(cv=KFold(n_splits=10, random_state=... scoring='adjusted_mutual_info_score', verbose=0), X=          dept  custody_type  facility      race...9  1.287418  1.595334  \n\n[6183 rows x 10 columns], y=None, groups=None, **fit_params={})\n    634                                   return_train_score=self.return_train_score,\n    635                                   return_n_test_samples=True,\n    636                                   return_times=True, return_parameters=False,\n    637                                   error_score=self.error_score)\n    638           for parameters, (train, test) in product(candidate_params,\n--> 639                                                    cv.split(X, y, groups)))\n        cv.split = <bound method _BaseKFold.split of KFold(n_splits=10, random_state=11, shuffle=True)>\n        X =           dept  custody_type  facility      race...9  1.287418  1.595334  \n\n[6183 rows x 10 columns]\n        y = None\n        groups = None\n    640 \n    641         # if one choose to see train score, \"out\" will contain train score info\n    642         if self.return_train_score:\n    643             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\nC:\\Users\\Lara\\Miniconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV.fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nTypeError                                          Mon Jan 29 16:45:44 2018\nPID: 7568                 Python 3.6.3: C:\\Users\\Lara\\Miniconda3\\python.exe\n...........................................................................\nC:\\Users\\Lara\\Miniconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (AffinityPropagation(affinity='euclidean', conver....5, max_iter=50, preference=None, verbose='True'),           dept  custody_type  facility      race...9  1.287418  1.595334  \n\n[6183 rows x 10 columns], None, {'score': make_scorer(adjusted_mutual_info_score)}, array([   0,    2,    3, ..., 6180, 6181, 6182]), array([   1,    5,   15,   32,   36,   42,   47,...6135, 6139, 6149, 6152,\n       6158, 6161, 6162]), 0, {'convergence_iter': 7, 'damping': 0.5, 'max_iter': 50, 'verbose': 'True'}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Lara\\Miniconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (AffinityPropagation(affinity='euclidean', conver....5, max_iter=50, preference=None, verbose='True'),           dept  custody_type  facility      race...9  1.287418  1.595334  \n\n[6183 rows x 10 columns], None, {'score': make_scorer(adjusted_mutual_info_score)}, array([   0,    2,    3, ..., 6180, 6181, 6182]), array([   1,    5,   15,   32,   36,   42,   47,...6135, 6139, 6149, 6152,\n       6158, 6161, 6162]), 0, {'convergence_iter': 7, 'damping': 0.5, 'max_iter': 50, 'verbose': 'True'})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Lara\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=AffinityPropagation(affinity='euclidean', conver....5, max_iter=50, preference=None, verbose='True'), X=          dept  custody_type  facility      race...9  1.287418  1.595334  \n\n[6183 rows x 10 columns], y=None, scorer={'score': make_scorer(adjusted_mutual_info_score)}, train=array([   0,    2,    3, ..., 6180, 6181, 6182]), test=array([   1,    5,   15,   32,   36,   42,   47,...6135, 6139, 6149, 6152,\n       6158, 6161, 6162]), verbose=0, parameters={'convergence_iter': 7, 'damping': 0.5, 'max_iter': 50, 'verbose': 'True'}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    483                              \" make sure that it has been spelled correctly.)\")\n    484 \n    485     else:\n    486         fit_time = time.time() - start_time\n    487         # _score will return dict if is_multimetric is True\n--> 488         test_scores = _score(estimator, X_test, y_test, scorer, is_multimetric)\n        test_scores = {}\n        estimator = AffinityPropagation(affinity='euclidean', conver....5, max_iter=50, preference=None, verbose='True')\n        X_test =           dept  custody_type  facility      race...14  0.995641  0.142621  \n\n[619 rows x 10 columns]\n        y_test = None\n        scorer = {'score': make_scorer(adjusted_mutual_info_score)}\n        is_multimetric = True\n    489         score_time = time.time() - start_time - fit_time\n    490         if return_train_score:\n    491             train_scores = _score(estimator, X_train, y_train, scorer,\n    492                                   is_multimetric)\n\n...........................................................................\nC:\\Users\\Lara\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _score(estimator=AffinityPropagation(affinity='euclidean', conver....5, max_iter=50, preference=None, verbose='True'), X_test=          dept  custody_type  facility      race...14  0.995641  0.142621  \n\n[619 rows x 10 columns], y_test=None, scorer={'score': make_scorer(adjusted_mutual_info_score)}, is_multimetric=True)\n    518 \n    519     Will return a single float if is_multimetric is False and a dict of floats,\n    520     if is_multimetric is True\n    521     \"\"\"\n    522     if is_multimetric:\n--> 523         return _multimetric_score(estimator, X_test, y_test, scorer)\n        estimator = AffinityPropagation(affinity='euclidean', conver....5, max_iter=50, preference=None, verbose='True')\n        X_test =           dept  custody_type  facility      race...14  0.995641  0.142621  \n\n[619 rows x 10 columns]\n        y_test = None\n        scorer = {'score': make_scorer(adjusted_mutual_info_score)}\n    524     else:\n    525         if y_test is None:\n    526             score = scorer(estimator, X_test)\n    527         else:\n\n...........................................................................\nC:\\Users\\Lara\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _multimetric_score(estimator=AffinityPropagation(affinity='euclidean', conver....5, max_iter=50, preference=None, verbose='True'), X_test=          dept  custody_type  facility      race...14  0.995641  0.142621  \n\n[619 rows x 10 columns], y_test=None, scorers={'score': make_scorer(adjusted_mutual_info_score)})\n    546     \"\"\"Return a dict of score for multimetric scoring\"\"\"\n    547     scores = {}\n    548 \n    549     for name, scorer in scorers.items():\n    550         if y_test is None:\n--> 551             score = scorer(estimator, X_test)\n        score = undefined\n        scorer = make_scorer(adjusted_mutual_info_score)\n        estimator = AffinityPropagation(affinity='euclidean', conver....5, max_iter=50, preference=None, verbose='True')\n        X_test =           dept  custody_type  facility      race...14  0.995641  0.142621  \n\n[619 rows x 10 columns]\n    552         else:\n    553             score = scorer(estimator, X_test, y_test)\n    554 \n    555         if hasattr(score, 'item'):\n\nTypeError: __call__() missing 1 required positional argument: 'y_true'\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "param_grid = {'damping': [0.5,0.75, 1], 'max_iter': [50, 100, 200, 300, 350], 'convergence_iter': [7, 15, 23], 'verbose':['True','False']}\n",
    "grid_aff(param_grid, train_cust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spectral clustering\n",
    "\n",
    "for k in range(2,11):\n",
    "    spect = SpectralClustering(n_clusters=k,random_state=11)\n",
    "    spect.fit_predict(train_cust)\n",
    "    spectlabel = spect.labels_\n",
    "    score=silhouette_score(train_cust, spectlabel, metric='euclidean')\n",
    "    print(\"The number of clusters, %d, and silhouette coefficient is %0.2f\" % (k,score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
